{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a1402a3",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/spraja08/Interpretable-GenAI/blob/main/resources/GenXAI%20Methods.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5dd6e4-ecfa-40c7-bdfa-20474607e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os, random, re, gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import machine_learning_datasets as mldatasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,\\\n",
    "      pipeline\n",
    "from bertviz import head_view, model_view\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase,\\\n",
    "      visualization\n",
    "from lit_nlp import notebook\n",
    "from lit_nlp.api import dataset as lit_dataset\n",
    "from lit_nlp.api import model as lit_model\n",
    "from lit_nlp.api import types as lit_types\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5dce17-46c3-48c5-a35b-4a9f1be8351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91851866-438c-4b4d-8681-31165f9ae1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use this sentiment analysis dataset and BERT model fine-tuned for the same task\n",
    "reviews_df = mldatasets.load(\"nyc-reviews\", prepare=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d80ed-ceda-473a-a570-5b2366f366f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d127d-a4fc-4fd4-a638-5b371e65e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df[[\"review_title\", \"review_full\", \"positive_sentiment\", \"label\", \"score\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a1b077-204d-404d-876e-1869794c2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_cols_l = ['score','positive_sentiment','rating']\n",
    "\n",
    "summary_df = reviews_df.groupby('label')[sum_cols_l].\\\n",
    "                    agg({'score':['count','mean'], 'positive_sentiment':'mean',\\\n",
    "                         'rating':'mean'})\n",
    "summary_df.columns = ['count', 'avg. score', '% positive', 'avg. rating']\n",
    "\n",
    "summary_df.sort_values(by='avg. rating', ascending=False).style.\\\n",
    "  format({'count':'{:,}', 'avg. score':'{:.1%}', '% positive':'{:.1%}' , 'avg. rating':'{:.2f}'}).\\\n",
    "  bar(subset=['avg. score', '% positive', 'avg. rating'], color='#4EF', width=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec53911f-65b6-4459-b40e-375ef2090b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = 42\n",
    "os.environ['PYTHONHASHSEED']=str(rand)\n",
    "random.seed(rand)\n",
    "np.random.seed(rand)\n",
    "torch.manual_seed(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd74ac8-5438-40c1-bbb8-d1861ec1ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise the tokenizer and the model to be used in the mechanistic visualisation\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "goemotions_mdl_path = \"monologg/bert-base-cased-goemotions-ekman\"\n",
    "\n",
    "goemotions_tok = AutoTokenizer.from_pretrained(goemotions_mdl_path)\n",
    "goemotions_mdl = AutoModelForSequenceClassification.\\\n",
    "                              from_pretrained(goemotions_mdl_path,\n",
    "                                              output_attentions=True)\n",
    "goemotions_mdl = goemotions_mdl.to(device)\n",
    "goemotions_mdl.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f2cc9a-e3bd-4a16-bd66-b7dced594755",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = goemotions_mdl.config.num_hidden_layers\n",
    "num_attention_heads = goemotions_mdl.config.num_attention_heads\n",
    "\n",
    "print(f\"The model has {num_layers} layers.\")\n",
    "print(f\"Each layer has {num_attention_heads} attention heads.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdcf6a4-a82b-4c1f-a636-dcdad8e10825",
   "metadata": {},
   "outputs": [],
   "source": [
    "suprise_sample_reviews_l = [174067, 284154, 480395, 47659]\n",
    "line_pattern = r'(?<=[.!?])\\s+'\n",
    "sample_reviews_dict = {}\n",
    "\n",
    "for i, review_idx in enumerate(suprise_sample_reviews_l):\n",
    "    review_s = reviews_df.loc[review_idx, :]\n",
    "    sentiment = 'Positive' if review_s['positive_sentiment'] else 'Negative'\n",
    "    review_lines_l = re.split(line_pattern, review_s['review_full'], maxsplit=1)\n",
    "    review_txt = '\\r\\n\\t\\t'.join(review_lines_l)\n",
    "\n",
    "    print(f\"{review_s['restaurant_name']}\")\n",
    "    print(f\"\\tSentiment:\\t\\t{sentiment}\")\n",
    "    print(f\"\\tRating:\\t\\t\\t{review_s['rating']}\")\n",
    "    print(f\"\\tGoEmotions Label:\\t{review_s['label']}\")\n",
    "    print(f\"\\tGoEmotions Score:\\t{review_s['score']:.1%}\")\n",
    "    print(f\"\\tTitle:\\t{review_s['review_title']}\")\n",
    "    print(f\"\\tReview:\\t{review_txt}\\r\\n\")\n",
    "\n",
    "    sample_reviews_dict[i] = review_lines_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476b319-e0d6-4eaa-871b-624bca2abdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_gpu_cache():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aff547-f7b7-409a-9133-0e6db961bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets just test if the model works to generate the expected sentiment. This is an encoder only model. \n",
    "#Learnt that for the purposes that involve non-generation of text (ex. classification), encoder only \n",
    "#models are sufficient.\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_output(tokenizer, model, sentences):\n",
    "    sentence_a, sentence_b = sentences\n",
    "\n",
    "    # Encode sentences with tokenizer\n",
    "    inputs = tokenizer.encode_plus(sentence_a, sentence_b,\\\n",
    "                                        return_tensors='pt')\n",
    "    # Extract components from inputs\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    token_type_ids = inputs['token_type_ids'].to(device)\n",
    "\n",
    "    # Get attention weights from model given the inputs\n",
    "    output = model(input_ids, token_type_ids=token_type_ids)\n",
    "    logits = output[0]\n",
    "    probabilities = F.softmax(logits, dim=-1)\n",
    "    predicted_class_index = torch.multinomial(probabilities, num_samples=1)\n",
    "    id2label = model.config.id2label[predicted_class_index.tolist()[0][0]]\n",
    "    return id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21380939-c924-4674-bbd7-53d4f9447218",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = get_output(goemotions_tok, goemotions_mdl,\\\n",
    "               sample_reviews_dict[1])\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1c2e3-8dd1-4b39-963c-0b017c91ff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar to the above, this invokes the model and gets the additional goodies - the parameters in all layers  \n",
    "\n",
    "def view_attention(tokenizer, model, sentences, view='model'):\n",
    "    sentence_a, sentence_b = sentences\n",
    "\n",
    "    # Encode sentences with tokenizer\n",
    "    inputs = tokenizer.encode_plus(sentence_a, sentence_b,\\\n",
    "                                        return_tensors='pt')\n",
    "    # Extract components from inputs\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    token_type_ids = inputs['token_type_ids'].to(device)\n",
    "\n",
    "    # Get attention weights from model given the inputs\n",
    "    attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "\n",
    "    # Get 2nd sentence start and tokens\n",
    "    sentence_b_start = token_type_ids[0].tolist().index(1)\n",
    "    input_id_list = input_ids[0].tolist()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "\n",
    "    # BertViz visualizers\n",
    "    if view=='head':\n",
    "        head_view(attention, tokens, sentence_b_start)\n",
    "    elif view=='model':\n",
    "        model_view(attention, tokens, sentence_b_start)\n",
    "    del attention\n",
    "    del tokens\n",
    "    clear_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c582356-b720-4df0-9331-ab534c9081d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view_attention(goemotions_tok, goemotions_mdl,\\\n",
    "               sample_reviews_dict[0], view='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81638d8d-9aba-45bc-9b0d-423b93e1996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_attention(goemotions_tok, goemotions_mdl,\\\n",
    "               sample_reviews_dict[0], view='head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1719db-84d4-4ec9-8d3b-c8b3e801d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_attention(goemotions_tok, goemotions_mdl,\\\n",
    "               sample_reviews_dict[1], view='head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a548b82-7039-45b9-b666-d9f0ade3289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "goemotions = pipeline(\n",
    "                      model=goemotions_mdl,\n",
    "                      tokenizer=goemotions_tok,\n",
    "                      task=\"text-classification\",\n",
    "                      function_to_apply='softmax',\n",
    "                      device=device,\n",
    "                      top_k=None\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e1d7d3-cfab-4b32-964d-a8fbc2bf4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "goemotions(['this restaurant was unexpectedly disgusting!',\\\n",
    "            'this restaurant was shockingly amazing!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba73bf-dd4f-4d3a-86ac-d94be4b31028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are moving into Token Attribution techniques - the gradient attribution.\n",
    "\n",
    "def visualize_ig_review(interpret_s:pd.Series,\n",
    "                        pline:pipeline,\n",
    "                        max_prob_thresh:float=0.1,\n",
    "                        max_classes=np.PINF,\n",
    "                        concat_title=True,\n",
    "                        summary_df=None\n",
    "                    ) -> pd.DataFrame:\n",
    "    print(f\"{interpret_s.name}: {interpret_s['restaurant_name']}\")\n",
    "\n",
    "    # Init some variables\n",
    "    if concat_title:\n",
    "        text = interpret_s['review_title'] + ': ' + interpret_s['review_full']\n",
    "    else:\n",
    "        text = interpret_s['review_full']\n",
    "    true_label = 'Positive' if interpret_s['positive_sentiment'] else 'Negative'\n",
    "    rating = interpret_s['rating']\n",
    "\n",
    "    # Get Predictions\n",
    "    prediction = pline(text)[0]\n",
    "    prediction_df = pd.DataFrame(prediction)\n",
    "    if summary_df is not None:\n",
    "        prediction_df['label_avg_rating'] = prediction_df.label.\\\n",
    "                                                replace(summary_df['avg. rating'].to_dict())\n",
    "        prediction_df = prediction_df.sort_values('label_avg_rating', ascending=False).\\\n",
    "                                                                        reset_index(drop=True)\n",
    "\n",
    "    # Process Predictions\n",
    "    prediction_tuples = [(p['label'], p['score']) for p in prediction]\n",
    "    sorted_prediction_tuples = sorted(prediction_tuples, key=lambda x: x[1], reverse=True)\n",
    "    pred_class, pred_prob = sorted_prediction_tuples[0]\n",
    "\n",
    "    # Initialize Integrated Gradients\n",
    "    forward_func = lambda inputs, position=0: pline.model(inputs,\\\n",
    "                              attention_mask=torch.ones_like(inputs))[position]\n",
    "    layer = getattr(pline.model, 'bert').embeddings\n",
    "    lig = LayerIntegratedGradients(forward_func, layer)\n",
    "\n",
    "    # Prepare tokens and baseline\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = torch.tensor(pline.tokenizer.encode(text, add_special_tokens=False), device = device).unsqueeze(0)\n",
    "    tokens = pline.tokenizer.convert_ids_to_tokens(inputs.detach().cpu().numpy()[0])\n",
    "    sequence_len = inputs.shape[1]\n",
    "    baseline = torch.tensor([pline.tokenizer.cls_token_id] + [pline.tokenizer.pad_token_id] *\\\n",
    "                            (sequence_len - 2) + [pline.tokenizer.sep_token_id], device=device).\\\n",
    "                                    unsqueeze(0)\n",
    "\n",
    "    clear_gpu_cache()\n",
    "\n",
    "    # Iterate over every prediction\n",
    "    vis_record_l = []\n",
    "    for i, (attr_class, attr_score) in enumerate(sorted_prediction_tuples):\n",
    "        if (attr_score > max_prob_thresh) and (i < max_classes):\n",
    "            # Sets the Target Class\n",
    "            target = pline.model.config.label2id[attr_class]\n",
    "\n",
    "            # Get Attributions\n",
    "            with torch.no_grad():\n",
    "                attributes, delta = lig.attribute(inputs=inputs,\n",
    "                                                baselines=baseline,\n",
    "                                                target=target,\n",
    "                                                return_convergence_delta = True)\n",
    "\n",
    "            # Post-Processing Attributions\n",
    "            attr = attributes.sum(dim=2).squeeze(0)\n",
    "            attr = attr / torch.norm(attr)\n",
    "            attr = attr.cpu().detach().numpy()\n",
    "\n",
    "            # Generate & Append Visualization Data Record\n",
    "            vis_record = visualization.VisualizationDataRecord(\n",
    "                                    word_attributions=attr,\n",
    "                                    pred_prob=pred_prob,\n",
    "                                    pred_class=pred_class,\n",
    "                                    true_class=f\"{true_label} ({rating})\",\n",
    "                                    attr_class=attr_class,\n",
    "                                    attr_score=attr_score,\n",
    "                                    raw_input_ids=tokens,\n",
    "                                    convergence_score=delta)\n",
    "            vis_record_l.append(vis_record)\n",
    "\n",
    "    # Display List of Visualization Data Records\n",
    "    _ = visualization.visualize_text(vis_record_l)\n",
    "\n",
    "    clear_gpu_cache()\n",
    "\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0aaee7-40d3-4a1b-8cef-f51512f5c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_suprise_df = reviews_df[(reviews_df['label']=='surprise') &\\\n",
    "                                (reviews_df['score']>0.9) &\\\n",
    "                                (reviews_df['positive_sentiment']==0) &\\\n",
    "                                (reviews_df['rating']<3)]\n",
    "neg_suprise_samp_df = neg_suprise_df.sample(n=10, random_state=rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af351831-ae19-4141-bd7a-7864e52d4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    sample_to_interpret = neg_suprise_samp_df.iloc[i]\n",
    "    _ = visualize_ig_review(sample_to_interpret, goemotions,\\\n",
    "                            concat_title=True, summary_df=summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdffac7-47d6-4f66-a025-72a8f3aa6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_suprise_df = reviews_df[(reviews_df['label']=='surprise') &\\\n",
    "                                (reviews_df['score']>0.97) &\\\n",
    "                                (reviews_df['positive_sentiment']==1) &\\\n",
    "                                (reviews_df['rating']>4)]\n",
    "pos_suprise_samp_df = pos_suprise_df[~pos_suprise_df['review_full'].\\\n",
    "                                       str.contains('surprise')]\n",
    "\n",
    "for i in range(10):\n",
    "    sample_to_interpret = pos_suprise_samp_df.iloc[i]\n",
    "    _ = visualize_ig_review(sample_to_interpret, goemotions,\\\n",
    "                            concat_title=False, summary_df=summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a045152-3dc2-45e1-bfd8-ca779ad7297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mixed_samp_df = reviews_df[(~reviews_df['label'].isin(['neutral','joy'])) &\\\n",
    "                              (reviews_df['score'] < 0.5) &\\\n",
    "                              (reviews_df['positive_sentiment']==1) &\\\n",
    "                              (reviews_df['rating']< 5)].sample(n=10,\\\n",
    "                                                                   random_state=rand)\n",
    "neg_mixed_samp_df = reviews_df[(~reviews_df['label'].isin(['neutral','joy'])) &\\\n",
    "                              (reviews_df['score'] < 0.5) &\\\n",
    "                              (reviews_df['positive_sentiment']==0) &\\\n",
    "                              (reviews_df['rating']>2)].sample(n=10,\\\n",
    "                                                                  random_state=rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e5d8a8-aa0f-4c8a-94c8-2ef0b6420323",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    sample_to_interpret = pos_mixed_samp_df.iloc[i]\n",
    "    prediction_df = visualize_ig_review(sample_to_interpret, goemotions,\\\n",
    "                                        concat_title=False, summary_df=summary_df)\n",
    "    rest_name = sample_to_interpret['restaurant_name']\n",
    "    mldatasets.plot_polar(prediction_df, 'score', 'label', name=rest_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c3597-e4a9-4916-be8b-e87b83c909ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GEDataset(lit_dataset.Dataset):\n",
    "\n",
    "    GE_LABELS = ['anger', 'disgust', 'fear', 'joy',\\\n",
    "                 'neutral', 'sadness', 'surprise']\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self._examples = [{\n",
    "          'review': row['review_title'] + ': ' + row['review_full'],\n",
    "          'label': row['label'],\n",
    "          'rating': row['rating'],\n",
    "          'positive': row['positive_sentiment']\n",
    "        } for _, row in df.iterrows()]\n",
    "\n",
    "    def spec(self):\n",
    "        return {\n",
    "          'review': lit_types.TextSegment(),\n",
    "          'label': lit_types.CategoryLabel(vocab=self.GE_LABELS),\n",
    "          'rating': lit_types.CategoryLabel(),\n",
    "          'positive': lit_types.CategoryLabel()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754f767-e92c-44e2-922a-03f0fbf905d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GEModel(lit_model.Model):\n",
    "\n",
    "    GE_LABELS = ['anger', 'disgust', 'fear', 'joy',\\\n",
    "                 'neutral', 'sadness', 'surprise']\n",
    "\n",
    "    def __init__(self, model, tokenizer, **kw):\n",
    "        self._model = pipeline(\n",
    "                          model=model,\n",
    "                          tokenizer=tokenizer,\n",
    "                          task=\"text-classification\",\n",
    "                          function_to_apply=\"softmax\",\n",
    "                          device=device,\n",
    "                          top_k=None\n",
    "                        )\n",
    "\n",
    "    def input_spec(self):\n",
    "        return {\n",
    "            'review': lit_types.TextSegment()\n",
    "        }\n",
    "\n",
    "    def output_spec(self):\n",
    "        return {\n",
    "          'probas': lit_types.MulticlassPreds(vocab=self.GE_LABELS, parent='label')\n",
    "        }\n",
    "\n",
    "    def predict_minibatch(self, inputs):\n",
    "        examples = [d['review'] for d in inputs]\n",
    "        with torch.no_grad():\n",
    "            preds = self._model(examples)\n",
    "        preds = [{p['label']:p['score'] for p in pred_dicts}\\\n",
    "                 for pred_dicts in preds]\n",
    "        preds = [dict(sorted(pred_dict.items()))\\\n",
    "                 for pred_dict in preds]\n",
    "        preds = [{'probas': list(pred_dict.values())} for pred_dict in preds]\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac5b37-b81e-4d39-9a60-0c67ac2e4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lit_nlp\n",
    "models = {'GoEmotion':GEModel(goemotions_mdl, goemotions_tok)}\n",
    "\n",
    "samples100_df = pd.concat([neg_suprise_samp_df, pos_suprise_samp_df, neg_mixed_samp_df,\\\n",
    "                           pos_mixed_samp_df, reviews_df.sample(n=60, random_state=rand)])\n",
    "\n",
    "datasets = {'NYCRestaurants':GEDataset(samples100_df)}\n",
    "widget = notebook.LitWidget(models, datasets, port = 8890)\n",
    "widget.render(height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ad7af-b057-46d4-9544-3137b13cb75a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genxai",
   "language": "python",
   "name": "genxai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
