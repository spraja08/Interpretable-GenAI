{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "387e6237-b616-40df-a697-6fc8f514b0f8",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This is a self-correcting RAG pattern that checks the retrieved contexts for relevancy and the generated answers for hallucinations.\\\n",
    "It is loosely based on this Self-RAG [paper](https://arxiv.org/abs/2310.11511)\n",
    "\n",
    "![flow](resource/flow.png)\n",
    "\n",
    "The LLM used in this is llama3. The embedding model used is mxbai-embed-large (dim is 1024).\\\n",
    "Both are ran locally using ollama:\\\n",
    "a) Install ollama\\\n",
    "b) Pull llama3 and mxbai-embed-large (ollama pull...)\n",
    "\n",
    "Run the agentic_rag_index notebook before this to index and persist the context docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7109ebc1-36a7-4ad7-8ab1-9bb9bbb3249b",
   "metadata": {},
   "source": [
    "### Build the Execution Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70cf04e3-75e2-43e3-b6ea-cbee45b51758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---LOADING INDEX FROM PERSISTENNT STORE---\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from agentic_rag_helper import Helper\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "    context: List[str]\n",
    "    quality: str\n",
    "\n",
    "\n",
    "#retriever = retrieved_index.as_retriever()\n",
    "helper = Helper()\n",
    "helper.load_index(\"index\")\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"check_guardrails\", helper.guardtail_check) \n",
    "workflow.add_node(\"retrieve_context\", helper.retrieve_context) \n",
    "workflow.add_node(\"grade_documents\", helper.grade_chunks) \n",
    "workflow.add_node(\"generate\", helper.generate) \n",
    "workflow.add_node(\"grade_hallucination\", helper.grade_hallucination) \n",
    "\n",
    "workflow.set_entry_point(\"check_guardrails\")\n",
    "#workflow.add_edge(\"check_guardrails\", \"retrieve_context\")\n",
    "workflow.add_edge(\"retrieve_context\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_guardrails\",\n",
    "    helper.guardrail_decision,\n",
    "    {\n",
    "        \"stop\": END,\n",
    "        \"retrieve_context\": \"retrieve_context\",\n",
    "    }\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    helper.generation_decision,\n",
    "    {\n",
    "        \"stop\": END,\n",
    "        \"generate\": \"generate\",\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"generate\", \"grade_hallucination\")\n",
    "workflow.add_edge(\"grade_hallucination\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace34d27-3792-40a5-9769-1db55dc4d1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK FOR TOXICITY---\n",
      "---CLASSIFICASTION is NON_TOXIC--\n",
      "'Finished running: check_guardrails'\n",
      "---RETRIEVE---\n",
      "'Finished running: retrieve_context'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "And the 3rd and the 4th are fundamentally similar in the approach. Therefore we can now reduce the categories into two to move forward — 1/symbol manipulation and; 2/sequence transduction using pattern matching. Now, it is important to understand the limitations of both these approaches to avoid rude shocks. In the first symbol manipulation approach, the trouble is the knowledge engineering bottleneck. Until the system assembles a critical mass of axioms, it would not be useful. Humanly seeding such an axiom base has folded in the past (refer to Tim Berners Lee’s earlier attempt at creating the Semantic Web). As a side story, I attempted to solve this problem using NLP to create the axioms as mentioned in the beginning of this article and could only achieve a limited success in a couple of narrow domains. The sequence transduction approach on the other hand lacks causality and it hallucinates. Both these are serious limitations. Those who know the math behind the LLMs understand how simple and dumb the structure of knowledge representation inside is and how challenging it would be to model chains of causes and effects. This is not a new problem. The linguists calls this Anaphora Resolution and it was recognised as the hard problem during the early NLP days itself.\n",
      "\n",
      "Imagine a machine processing this statement — “I went to the movies last night but the tickets were sold out”. The semantic link missing in this statement is that one needs to buy tickets to get access to the movies. This is one degree of causality. Humans maintain and process massive chains of causalities in our reasoning. Relating statistical correlation scores of n-grams appearing in sentences using multi-dimensional matrices fails in representing such rich semantic relationships. Now, where it becomes problematic is when LLMs makes up the best guess using the closest patterns when it can’t find any tighter correlations. In strict mathematical terms, these are prediction errors but the industry chooses to call it as hallucination! When I was 6 years old, I was curious to find out how Nehru (the first Prime Minister of India) died. My uncle told me that Nehru got old, his eye-sight was so degraded that he fell in to a ditch while walking and died. Growing up in a god-forsaken rural part of the world, my uncle would have come across cases of old men going blind and dying in such unfortunate accidents. Although he did not have actual facts about Nehru’s death, he had great language skills to spin compelling narratives and those closely matching patterns. The combination of these resulted in this hallucination (actually a lie?). As a 6 year old, I fell for that eloquence and completely trusted him. I narrated that ‘fact’’ to my school teacher a few years down the line very confidently and the resultant awkward embarrassment stays with me forever. (Oh, Nehru died of heart failure while he was still a Prime Minister). Even a few days back, I was asking openAI to summarise a bunch of research papers for me. \n",
      "{'score': 'yes'}\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "It gave me compelling answers that I fell for. When I read the actual papers later, I realised how completely wrong they were and felt like that same embarrassed and disappointed child.\n",
      "\n",
      "Now, I am not a bitter road block prophet here. \n",
      "{'score': 'yes'}\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "'Finished running: grade_documents'\n",
      "---GENERATE---\n",
      "Generated. Question: Has the author been wrong before? Explain the incidence where the author was wrong, Answer: { \"Has the author been wrong before? Explain the incidence where the author was wrong\" : \"Yes, according to the context, the author has been wrong before. The author shares a personal anecdote about being misled by their uncle's narrative when they were 6 years old. Their uncle told them that Nehru, the first Prime Minister of India, died after falling into a ditch while walking due to his poor eyesight, which was actually a lie. The author fell for this story and repeated it confidently in school, only to later discover the actual cause of Nehru's death was heart failure. This experience left the author feeling embarrassed and disappointed.\" }\n",
      "'Finished running: generate'\n",
      "---CHECK HALLUCINATIONS---\n",
      "{'score': 'yes'}\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "'Finished running: grade_hallucination'\n",
      "('{ \"Has the author been wrong before? Explain the incidence where the author '\n",
      " 'was wrong\" : \"Yes, according to the context, the author has been wrong '\n",
      " 'before. The author shares a personal anecdote about being misled by their '\n",
      " \"uncle's narrative when they were 6 years old. Their uncle told them that \"\n",
      " 'Nehru, the first Prime Minister of India, died after falling into a ditch '\n",
      " 'while walking due to his poor eyesight, which was actually a lie. The author '\n",
      " 'fell for this story and repeated it confidently in school, only to later '\n",
      " \"discover the actual cause of Nehru's death was heart failure. This \"\n",
      " 'experience left the author feeling embarrassed and disappointed.\" }')\n"
     ]
    }
   ],
   "source": [
    "app = workflow.compile()\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "inputs = {\"question\": \"Has the author been wrong before? Explain the incidence where the author was wrong\"}\n",
    "#inputs = {\"question\": \"adjusting the heat using thermostats?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}\")\n",
    "if(len(value['context']) == 0):\n",
    "    pprint(\"No Relevant Chunks available in the Knowledgebase\")\n",
    "else:\n",
    "    pprint(value[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102ac4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genxai",
   "language": "python",
   "name": "genxai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
